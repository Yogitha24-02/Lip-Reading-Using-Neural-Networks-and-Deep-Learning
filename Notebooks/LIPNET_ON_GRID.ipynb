{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbT_SauE7Ei_"
      },
      "source": [
        "#Downloading the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moFs5Pfn4DSL"
      },
      "outputs": [],
      "source": [
        "!wget 'https://spandh.dcs.shef.ac.uk/gridcorpus/s5/video/s5.mpg_vcd.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZgbF59N4Sj7"
      },
      "outputs": [],
      "source": [
        "!wget 'https://spandh.dcs.shef.ac.uk/gridcorpus/s20/video/s20.mpg_vcd.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9XryzB74THQ"
      },
      "outputs": [],
      "source": [
        "!wget 'https://spandh.dcs.shef.ac.uk/gridcorpus/s30/video/s30.mpg_vcd.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDYEURSN4tl6"
      },
      "outputs": [],
      "source": [
        "!wget 'https://spandh.dcs.shef.ac.uk/gridcorpus/s5/align/s5.tar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ua6FIclt4to6"
      },
      "outputs": [],
      "source": [
        "!wget 'https://spandh.dcs.shef.ac.uk/gridcorpus/s20/align/s20.tar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obHkgPXt4ttu"
      },
      "outputs": [],
      "source": [
        "!wget 'https://spandh.dcs.shef.ac.uk/gridcorpus/s30/align/s30.tar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kt7eBJpE46c-"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/s5.mpg_vcd.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD-1hgbH46h5"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/s20.mpg_vcd.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09xDTuuA46pV"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/s30.mpg_vcd.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJcmReom5DUM"
      },
      "outputs": [],
      "source": [
        "!tar -xvf s5.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAFVqZ9H5DWe"
      },
      "outputs": [],
      "source": [
        "!tar -xvf s20.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV6n0DvY5Doa"
      },
      "outputs": [],
      "source": [
        "!tar -xvf s30.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_qXbMPw6_pe"
      },
      "source": [
        "# Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFFNwT1r7O9r",
        "outputId": "d1556a38-3d36-4f4c-d51b-661fa0d781ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 75, 46, 140, 128   3584      \n",
            "                             )                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 75, 46, 140, 128   0         \n",
            "                             )                                   \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3  (None, 75, 23, 70, 128)   0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 75, 23, 70, 256)   884992    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 75, 23, 70, 256)   0         \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPoolin  (None, 75, 11, 35, 256)   0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 75, 11, 35, 75)    518475    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 75, 11, 35, 75)    0         \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPoolin  (None, 75, 5, 17, 75)     0         \n",
            " g3D)                                                            \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 75, 6375)          0         \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 75, 256)           6660096   \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 75, 256)           0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 75, 256)           394240    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 75, 256)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 75, 41)            10537     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8471924 (32.32 MB)\n",
            "Trainable params: 8471924 (32.32 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8hF9H_27O7h"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from typing import List\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]\n",
        "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
        "# Mapping integers back to original characters\n",
        "num_to_char = tf.keras.layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qzndJR27O5H"
      },
      "outputs": [],
      "source": [
        "def load_alignments(path:str) -> List[str]:\n",
        "    #print(path)\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    tokens = []\n",
        "    for line in lines:\n",
        "        line = line.split()\n",
        "        if line[2] != 'sil':\n",
        "            tokens = [*tokens,' ',line[2]]\n",
        "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9IGlKQZ7O2v"
      },
      "outputs": [],
      "source": [
        "yhat = model.predict(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AXWwV_e7OSX"
      },
      "outputs": [],
      "source": [
        "decoded = tf.keras.backend.ctc_decode(yhat,input_length = [75],greedy=True)[0][0].numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh-ptPLN7eDw"
      },
      "outputs": [],
      "source": [
        "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxiGk-de7eGK"
      },
      "outputs": [],
      "source": [
        "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in [alignments]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCMv2Trz7eId"
      },
      "outputs": [],
      "source": [
        "model.save('lipnet_grid_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9j5AiDd7eKp"
      },
      "outputs": [],
      "source": [
        "cropping_dictionary = {}\n",
        "cropping_dictionary['s30'] = (200,246,80,220)\n",
        "cropping_dictionary['s5'] = (210,256,120,260)\n",
        "cropping_dictionary['s20'] = (200,246,120,260)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcPAs4H67pVq"
      },
      "outputs": [],
      "source": [
        "def load_video(path):\n",
        "    print(path)\n",
        "    folder_name = path.split('/')[-2]\n",
        "    a,b,c,d = cropping_dictionary[folder_name]\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "        ret, frame = cap.read()\n",
        "        frame = tf.image.rgb_to_grayscale(frame)\n",
        "        frames.append(frame[a:b,c:d,:])\n",
        "    cap.release()\n",
        "    mean = tf.math.reduce_mean(frames)\n",
        "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
        "    return tf.cast((frames - mean), tf.float32) / std\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwBjE6IP7pX-"
      },
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "  path = bytes.decode(path.numpy())\n",
        "  file_name = path.split('/')[-1].split('.')[0]\n",
        "  folder_name = path.split('/')[-2]\n",
        "  video_path = os.path.join(path)\n",
        "  try:\n",
        "    alignment_path = os.path.join(f'/content/alignment/{folder_name}/align',f'{file_name}.align')\n",
        "    frames = load_video(video_path)\n",
        "    alignments = load_alignments(alignment_path)\n",
        "  except:\n",
        "    return tf.zeros((75,46,140,1)),tf.zeros((40),dtype= tf.int32)\n",
        "  return frames, alignments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2q_Iaf8u7paJ"
      },
      "outputs": [],
      "source": [
        "def mappable_function(path):\n",
        "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtA24_Iy7tlA"
      },
      "source": [
        "# Creating Tf Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSTa659y8BZD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZjw5wJm8Bba"
      },
      "outputs": [],
      "source": [
        "data = tf.data.Dataset.list_files('./data/*/*.mpg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4q0H1Ac8Bfs"
      },
      "outputs": [],
      "source": [
        "for i in data:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aa0TyW9u8BjE"
      },
      "outputs": [],
      "source": [
        "data = data.shuffle(10000, reshuffle_each_iteration=False)\n",
        "data = data.map(mappable_function)\n",
        "data = data.padded_batch(2, padded_shapes=([75,None,None,None],[40]))\n",
        "data = data.prefetch(tf.data.AUTOTUNE)\n",
        "train = data.take(9500)\n",
        "test = data.skip(9500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSfbqf0Z8JOz"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjgE5LwC8KXD"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
        "from tensorflow.keras.optimizers import Adam "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XK3sRize8Ni5"
      },
      "outputs": [],
      "source": [
        "def CTCLoss(y_true, y_pred):\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL0jZb818Nnk"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.01), loss=CTCLoss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKRFiAPV8V7b",
        "outputId": "5d4be1b1-1633-4134-9e65-cd12f460ae02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 79/950 [=>............................] - ETA: 13:57 - loss: 104.4280"
          ]
        }
      ],
      "source": [
        "history = model.fit(train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRzhelGwX242",
        "outputId": "22062712-d5aa-4889-d23b-fad9a3c3bc9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LSj1i7HX7aX",
        "outputId": "f8a935b5-e1fb-4946-8f21-c0f728b1e862"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('Lipnet_10epochs_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np51NwX6_yw6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_35s7P8WYa2y"
      },
      "outputs": [],
      "source": [
        "plt.plt(history.hi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu0fmZSkkumB"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyOarvqFkvdd"
      },
      "outputs": [],
      "source": [
        "sample = data.as_numpy_iterator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwsnqLgjkxG_"
      },
      "outputs": [],
      "source": [
        "val = sample.next(); val[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_GCxT_dkxLJ",
        "outputId": "1e5769f1-b508-4d97-acb0-4804c8ff935c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 309ms/step\n"
          ]
        }
      ],
      "source": [
        "yhat = model.predict(val[0\n",
        "                         ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hBKOR7tkxNk",
        "outputId": "3f06330a-7abf-465d-c33b-a99ac2835e03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'binc   bbeee bbi      nnne   aoin'>"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.strings.reduce_join([num_to_char(x) for x in tf.argmax(yhat[0],axis=1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlJVxA2ikxPk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
